{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import necessary libraries"
      ],
      "metadata": {
        "id": "ZddX0hscMqB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"
      ],
      "metadata": {
        "id": "XwhTx6zzL268"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the diabetes dataset"
      ],
      "metadata": {
        "id": "NT9Vs0ZFM3w4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/diabetes.csv')"
      ],
      "metadata": {
        "id": "5voGhJNHL6Lg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Create multiple versions of the dataset"
      ],
      "metadata": {
        "id": "4f0cDqwfM62H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Original: Keep raw data**"
      ],
      "metadata": {
        "id": "VM8dsRlvM9aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_original = df.copy()"
      ],
      "metadata": {
        "id": "DymsQN4vL85m"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Manual Cleaning: Remove biologically implausible values**"
      ],
      "metadata": {
        "id": "X8CxCeZyNGZx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_manual = df.copy()\n",
        "df_manual = df_manual[df_manual['Pregnancies'] <= 13]  # Max realistic pregnancies\n",
        "df_manual = df_manual[df_manual['Glucose'] != 0]       # Remove zero glucose\n",
        "df_manual = df_manual[df_manual['BloodPressure'] >= 40]  # Min realistic blood pressure\n",
        "df_manual = df_manual[(df_manual['SkinThickness'] != 0) & (df_manual['SkinThickness'] != 99)]  # Remove invalid skin thickness\n",
        "df_manual = df_manual[(df_manual['Insulin'] != 0) & (df_manual['Insulin'] <= 500)]  # Remove zero or extreme insulin\n",
        "df_manual = df_manual[(df_manual['BMI'] != 0) & (df_manual['BMI'] < 53.2)]  # Remove zero or extreme BMI\n",
        "df_manual = df_manual[(df_manual['DiabetesPedigreeFunction'] >= 0.1) & (df_manual['DiabetesPedigreeFunction'] <= 2.0)]  # Realistic pedigree range\n",
        "print(f\"Manual Cleaning: {len(df_manual)} rows remaining (from {len(df)})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29H0jn17MAjW",
        "outputId": "7a333142-de08-4ed5-f477-97611e1191a7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Manual Cleaning: 367 rows remaining (from 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Clipping: Cap outliers using IQR**"
      ],
      "metadata": {
        "id": "DitHjh05NPqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_clip = df.copy()\n",
        "numeric_cols = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n",
        "for col in numeric_cols:\n",
        "    Q1 = df_clip[col].quantile(0.25)\n",
        "    Q3 = df_clip[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "    df_clip[col] = df_clip[col].clip(lower=lower, upper=upper)\n",
        "print(f\"Clipping: {len(df_clip)} rows remaining (from {len(df)})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNye1i7IMEcy",
        "outputId": "96e14f42-af29-44a6-a819-14a7fc976f2f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clipping: 768 rows remaining (from 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imputation: Replace zeros with median**"
      ],
      "metadata": {
        "id": "pDfYv-OfNT0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_impute = df.copy()\n",
        "cols_to_impute = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
        "for col in cols_to_impute:\n",
        "    median_val = df_impute[col].median()\n",
        "    df_impute[col] = df_impute[col].replace(0, median_val)\n",
        "print(f\"Imputation: {len(df_impute)} rows remaining (from {len(df)})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlOoEun7MIQ3",
        "outputId": "aa13f366-308d-4c90-e9bb-2980d9643bb0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imputation: 768 rows remaining (from 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Correlation analysis to understand feature importance\n"
      ],
      "metadata": {
        "id": "YPZUmIJPNYC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = {\n",
        "    'Original': df_original,\n",
        "    'Manual Cleaning': df_manual,\n",
        "    'Clipping': df_clip,\n",
        "    'Imputation': df_impute\n",
        "}\n",
        "for name, data in datasets.items():\n",
        "    print(f\"\\nCorrelation with 'Outcome' for {name}:\")\n",
        "    print(data.corr()['Outcome'].sort_values(ascending=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_56rtsm1MK6b",
        "outputId": "6e32daf1-a8e6-48c7-dc40-d01451538b24"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Correlation with 'Outcome' for Original:\n",
            "Outcome                     1.000000\n",
            "Glucose                     0.466581\n",
            "BMI                         0.292695\n",
            "Age                         0.238356\n",
            "Pregnancies                 0.221898\n",
            "DiabetesPedigreeFunction    0.173844\n",
            "Insulin                     0.130548\n",
            "SkinThickness               0.074752\n",
            "BloodPressure               0.065068\n",
            "Name: Outcome, dtype: float64\n",
            "\n",
            "Correlation with 'Outcome' for Manual Cleaning:\n",
            "Outcome                     1.000000\n",
            "Glucose                     0.515473\n",
            "Age                         0.349566\n",
            "Insulin                     0.320706\n",
            "Pregnancies                 0.265999\n",
            "BMI                         0.248377\n",
            "SkinThickness               0.223329\n",
            "BloodPressure               0.217601\n",
            "DiabetesPedigreeFunction    0.206793\n",
            "Name: Outcome, dtype: float64\n",
            "\n",
            "Correlation with 'Outcome' for Clipping:\n",
            "Outcome                     1.000000\n",
            "Glucose                     0.479158\n",
            "BMI                         0.309739\n",
            "Age                         0.242702\n",
            "Pregnancies                 0.220392\n",
            "DiabetesPedigreeFunction    0.184969\n",
            "Insulin                     0.124721\n",
            "BloodPressure               0.113301\n",
            "SkinThickness               0.073125\n",
            "Name: Outcome, dtype: float64\n",
            "\n",
            "Correlation with 'Outcome' for Imputation:\n",
            "Outcome                     1.000000\n",
            "Glucose                     0.492782\n",
            "BMI                         0.312249\n",
            "Age                         0.238356\n",
            "Pregnancies                 0.221898\n",
            "SkinThickness               0.189065\n",
            "DiabetesPedigreeFunction    0.173844\n",
            "BloodPressure               0.165723\n",
            "Insulin                     0.148457\n",
            "Name: Outcome, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Function to evaluate Logistic Regression with tuning\n"
      ],
      "metadata": {
        "id": "s36WSlevNcMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_logistic_regression(df, name):\n",
        "    # Select top features based on correlation (e.g., top 5)\n",
        "    corr = df.corr()['Outcome'].abs().sort_values(ascending=False)\n",
        "    top_features = corr[1:6].index.tolist()  # Exclude 'Outcome', take top 5\n",
        "    X = df[top_features]\n",
        "    y = df['Outcome']\n",
        "\n",
        "    # Scale features\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=0)\n",
        "\n",
        "    # Define parameter grid for tuning\n",
        "    param_grid = {\n",
        "        'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
        "        'class_weight': [None, 'balanced']  # Handle class imbalance\n",
        "    }\n",
        "\n",
        "    # Train Logistic Regression with GridSearchCV\n",
        "    model = LogisticRegression(max_iter=1000)\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=5, scoring='f1_weighted', n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Best model\n",
        "    best_model = grid_search.best_estimator_\n",
        "    print(f\"\\nBest Parameters for {name}: {grid_search.best_params_}\")\n",
        "\n",
        "    # Predict on test set\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\n📊 Results for {name}:\")\n",
        "    print(f\"Accuracy:  {accuracy*100:.2f}%\")\n",
        "    print(f\"Precision: {precision*100:.2f}%\")\n",
        "    print(f\"Recall:    {recall*100:.2f}%\")\n",
        "    print(f\"F1 Score:  {f1*100:.2f}%\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    return {'Name': name, 'Accuracy': accuracy, 'F1 Score': f1}"
      ],
      "metadata": {
        "id": "_hRAw-OFMOnQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Evaluate all datasets\n"
      ],
      "metadata": {
        "id": "hLy_XM1ENej8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for name, data in datasets.items():\n",
        "    result = evaluate_logistic_regression(data, name)\n",
        "    results.append(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap8m7AUuMZpu",
        "outputId": "46649ea0-0af4-423e-f807-b529f876cae3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best Parameters for Original: {'C': 1, 'class_weight': None}\n",
            "\n",
            "📊 Results for Original:\n",
            "Accuracy:  80.52%\n",
            "Precision: 79.87%\n",
            "Recall:    80.52%\n",
            "F1 Score:  79.79%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87       107\n",
            "           1       0.73      0.57      0.64        47\n",
            "\n",
            "    accuracy                           0.81       154\n",
            "   macro avg       0.78      0.74      0.75       154\n",
            "weighted avg       0.80      0.81      0.80       154\n",
            "\n",
            "\n",
            "Best Parameters for Manual Cleaning: {'C': 0.1, 'class_weight': None}\n",
            "\n",
            "📊 Results for Manual Cleaning:\n",
            "Accuracy:  81.08%\n",
            "Precision: 82.00%\n",
            "Recall:    81.08%\n",
            "F1 Score:  80.48%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.93      0.85        43\n",
            "           1       0.87      0.65      0.74        31\n",
            "\n",
            "    accuracy                           0.81        74\n",
            "   macro avg       0.83      0.79      0.80        74\n",
            "weighted avg       0.82      0.81      0.80        74\n",
            "\n",
            "\n",
            "Best Parameters for Clipping: {'C': 10, 'class_weight': None}\n",
            "\n",
            "📊 Results for Clipping:\n",
            "Accuracy:  80.52%\n",
            "Precision: 79.91%\n",
            "Recall:    80.52%\n",
            "F1 Score:  79.96%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.90      0.86       107\n",
            "           1       0.72      0.60      0.65        47\n",
            "\n",
            "    accuracy                           0.81       154\n",
            "   macro avg       0.78      0.75      0.76       154\n",
            "weighted avg       0.80      0.81      0.80       154\n",
            "\n",
            "\n",
            "Best Parameters for Imputation: {'C': 1, 'class_weight': None}\n",
            "\n",
            "📊 Results for Imputation:\n",
            "Accuracy:  80.52%\n",
            "Precision: 79.87%\n",
            "Recall:    80.52%\n",
            "F1 Score:  79.79%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.91      0.87       107\n",
            "           1       0.73      0.57      0.64        47\n",
            "\n",
            "    accuracy                           0.81       154\n",
            "   macro avg       0.78      0.74      0.75       154\n",
            "weighted avg       0.80      0.81      0.80       154\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Find best dataset"
      ],
      "metadata": {
        "id": "6LX-D551Ng41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(results)\n",
        "best_result = results_df.loc[results_df['F1 Score'].idxmax()]\n",
        "print(\"\\n✅ Best Dataset based on F1 Score:\")\n",
        "print(best_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8DyfZomM0lD",
        "outputId": "140db45d-1b67-4715-bf91-ae1e96fd2353"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Best Dataset based on F1 Score:\n",
            "Name        Manual Cleaning\n",
            "Accuracy           0.810811\n",
            "F1 Score           0.804847\n",
            "Name: 1, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0qpSVdCoMMwI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}